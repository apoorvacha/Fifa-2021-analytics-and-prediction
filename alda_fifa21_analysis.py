# -*- coding: utf-8 -*-
"""ALDA_FIFA21_ANALYSIS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tf6KZfpHceCDhwBAZihJc13_rCVqbY_H
"""

# Importing necessary libraries
import numpy as np
import pandas as pd
import os
from scipy import stats
import missingno as msno

# Importing libraries for visualisation
import matplotlib as mpl
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
sns.set(style='ticks', color_codes=True)
sns.set(style='darkgrid')
import plotly.graph_objs as go
import plotly.express as pe
import graphviz

# Importing libraries for training and testing
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn import tree,preprocessing, svm
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,roc_auc_score,auc,f1_score 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

#Import the FIFA 21 dataset
data = pd.read_csv(r'/content/drive/Shareddrives/FIFA21/players_21.csv')

#Check the summary statisticks of the dataset
data.head()

"""**Exploratory Data Analysis**"""

#Shape of the data
data.shape

#This shows we have 18944 rows or data objects and 106 attributes

#Creating a new dataset with the necessary player statistics attributes
columns = ['age', 'player_positions', 'height_cm', 'weight_kg', 'attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control', 'movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure', 'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning', 'goalkeeping_reflexes']
player_df = data[columns]
player_df.head()

def final_positions(row):
  positions = row['player_positions'].split(', ')
  N = len(positions)
  if N < 3:
    #If a player has only two positions, then we will consider the first position as the their main position
    pos = positions[0]
    if pos in ['ST', 'LW', 'RW', 'CF']:
      return 0
    elif pos in ['CAM', 'LM', 'CM', 'RM', 'CDM']:
      return 1
    elif pos in ['LWB', 'RWB', 'LB', 'CB', 'RB']:
      return 2
    elif pos in ['GK']:
      return 3
  else: #If a player has more than 3 positions
    pos_count = [0, 0, 0, 0]
    for pos in positions:
      if pos in ['ST', 'LW', 'RW', 'CF']:
        return 0
      elif pos in ['CAM', 'LM', 'CM', 'RM', 'CDM']:
        return 1 
      elif pos in ['LWB', 'RWB', 'LB', 'CB', 'RB']:
        return 2 
      elif pos in ['GK']:
        return 3 
      else:
        continue
      pos_count[index] += 1
    return pos_count.index(max(pos_count))

player_df['player_positions'] = player_df.apply(final_positions, axis=1)

# #Setting player positions
player_df.head()

#Get the info on the dataset
player_df.info()

#Player statistics
player_df.describe()

#Check Missing values in dataframe
player_df.isna().any()

#EDA
#Get value counts to identify number of players in different groups
player_df['player_positions'].value_counts()

#Player positon mapping
# 0 - Striker
# 1 - Midfielder
# 2 - Defender
# 3 - GoalKeeper

#The number of records for GK is less than the other groups and hence this will impact the results being skewed towards the heavy samples

#Plot a histogram to view the value distribution on the x axis

player_df.hist(figsize=(30,20), bins=40)
plt.show()

#We identify that each histogram has value range between 0 - 100 indicating that all the features are of same scale. Therefore we dont need to perform feature scaling

#Plot a graph for the value counts
plt.figure(figsize = (15,10))
plt.title("Number of players in different positions")
fig = sns.countplot(x = 'player_positions', data = player_df)

#Understand the corelation between all the features to identigy which features will impact the player positions more

#Drop categorical data
drop_elements = ['player_positions']
player_df_correlation=player_df.drop(drop_elements, axis = 1)

# Create the heat map of features correlation
colormap = plt.cm.BuGn
plt.figure(figsize=(14,12))
plt.title('Correlation of Features', y=1.05, size=15)
sns.heatmap(player_df_correlation.astype(float).corr(),linewidths=0.1,vmax=1.0, 
            square=True, cmap=colormap, linecolor='white', annot=False)

#Based on the above correlation heatmap, we understand which features are more closely related to each other. Lets plot the scatter plot for some of those features for a better understanding
#Plotting scatter plots bwtween some relevant features
g = sns.relplot(x="defending_sliding_tackle", 
                y="attacking_finishing", 
                hue="player_positions", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

g = sns.relplot(x="defending_sliding_tackle", 
                y="attacking_finishing", 
                hue="age", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

#Plotting scatter plots bwtween some relevant features
g = sns.relplot(x="attacking_finishing", 
                y="movement_sprint_speed", 
                hue="player_positions", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

g = sns.relplot(x="attacking_finishing", 
                y="movement_sprint_speed", 
                hue="age", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

#Plotting scatter plots bwtween some relevant features
g = sns.relplot(x="attacking_finishing", 
                y="attacking_short_passing", 
                hue="player_positions", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

g = sns.relplot(x="attacking_finishing", 
                y="attacking_short_passing", 
                hue="age", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

#Plotting scatter plots bwtween some relevant features
g = sns.relplot(x="power_strength", 
                y="mentality_interceptions", 
                hue="player_positions", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

g = sns.relplot(x="power_strength", 
                y="mentality_interceptions", 
                hue="age", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

#Plotting scatter plots bwtween some relevant features
g = sns.relplot(x="skill_fk_accuracy", 
                y="mentality_penalties", 
                hue="player_positions", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

g = sns.relplot(x="skill_fk_accuracy", 
                y="mentality_penalties", 
                hue="age", 
                kind="scatter", 
                style = 'player_positions',
                data=player_df, 
                alpha = 0.7)

#Plot Boxplots to understand how the physical features affect the player's position
f, axes = plt.subplots(2, 2, figsize=(15, 15), sharex=False)
sns.despine(left=True)
sns.boxplot('player_positions', 'age', data = player_df, ax=axes[0, 0])
sns.boxplot('player_positions', 'movement_agility', data = player_df, ax=axes[0, 1])
sns.boxplot('player_positions', 'height_cm', data = player_df, ax=axes[1, 0])
sns.boxplot('player_positions', 'weight_kg', data = player_df, ax=axes[1, 1])

plt.show()

player_df = player_df.drop(columns=['age', 'height_cm', 'weight_kg'])
player_df.columns

#Creating testing and training splits
#We will use stratified shuffle spliting to ensure that we have representation from each of the player positions. This will also ignore the case where we have even a fewer data for GK

split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)
for train_index, test_index in split.split(player_df, player_df["player_positions"]):
    stratified_training_set = player_df.loc[train_index]
    stratified_testing_set = player_df.loc[test_index]

#Check if stratification has included data from all categories of PrePos
print(stratified_training_set['player_positions'].value_counts())
print(stratified_testing_set['player_positions'].value_counts())

#Create Features and Target variable
X_train, y_train = stratified_training_set, stratified_training_set
y_train = y_train['player_positions']
del X_train['player_positions']

X_test, y_test = stratified_testing_set, stratified_testing_set
y_test = y_test['player_positions']
del X_test['player_positions']

X_train = X_train.values
y_train = y_train.values
X_test = X_test.values
y_test = y_test.values

# Plot the confusion matrix
def plot_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):
    df_cm = pd.DataFrame(
        confusion_matrix, index=class_names, columns=class_names, 
    )
    colormap = plt.cm.BuGn
    fig = plt.figure(figsize=figsize)
    sns.set(font_scale=1.4)
    try:
        heatmap = sns.heatmap(df_cm, annot=True, fmt="d", annot_kws={"size": 16}, cmap=colormap)
    except ValueError:
        raise ValueError("Confusion matrix values must be integers.")
    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)
    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    return fig

#Algorithm 1 - Logistic Regression

parameters = {
    'penalty' : ['l1','l2'], 
    'C': [0.1, 1, 10, 100],
    'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],
}

logReg = LogisticRegression()
clf = GridSearchCV(logReg, param_grid=parameters, scoring='accuracy', cv=5)

clf.fit(X_train, y_train)

print("Tuned Hyperparameters :", clf.best_params_)

#Using the Tuned Hyperparameters from the above step
clf = LogisticRegression(random_state=42, solver='lbfgs', max_iter=1000, penalty='l2', C=1000).fit(X_train, y_train)
prediction = clf.predict(X_test)

conf_mx = confusion_matrix(y_test, prediction)

positions = player_df["player_positions"].unique()
print(plot_confusion_matrix(conf_mx, class_names=positions))
print(" Accuracy: ",accuracy_score(y_test, prediction))
print(" F1 score: ",f1_score(y_test, prediction,average='weighted'))

# Algorithm 2 - Decision Trees

parameters = {
    'criterion' : ['gini','entropy'], 
    'max_depth' : range(1, 10)
}

decisionTree = tree.DecisionTreeClassifier()
clf = GridSearchCV(decisionTree, param_grid=parameters, scoring='accuracy', cv=10)

clf.fit(X_train, y_train)

print("Tuned Hyperparameters :", clf.best_params_)

clf = tree.DecisionTreeClassifier(criterion='entropy',splitter='best', random_state=42, max_depth=8).fit(X_train, y_train)
prediction = clf.predict(X_test)

conf_mx = confusion_matrix(y_test, prediction)

positions = player_df["player_positions"].unique()
print(plot_confusion_matrix(conf_mx, class_names=positions))
print(" Accuracy: ",accuracy_score(y_test, prediction))
print(" F1 score: ",f1_score(y_test, prediction,average='weighted'))

dot_data = tree.export_graphviz(clf, out_file=None, class_names=columns, filled=True, rounded=True, special_characters=True) 
graph = graphviz.Source(dot_data) 
graph

#Algorithm 3 - KNN

parameters = {
    'n_neighbors' : range(1,20), 
    'weights' : ['uniform', 'distance'],
    'metric' : ['euclidean', 'manhattan']
}

kNeighborsClassifier = KNeighborsClassifier()
clf = GridSearchCV(kNeighborsClassifier, param_grid=parameters, scoring='accuracy', cv=10)

clf.fit(X_train, y_train)

print("Tuned Hyperparameters :", clf.best_params_)

clf = KNeighborsClassifier(n_neighbors=15, metric='manhattan', weights='distance').fit(X_train, y_train)
prediction = clf.predict(X_test)

conf_mx = confusion_matrix(y_test, prediction)

positions = player_df["player_positions"].unique()
print(plot_confusion_matrix(conf_mx, class_names=positions))
print(" Accuracy: ",accuracy_score(y_test, prediction))
print(" F1 score: ",f1_score(y_test, prediction,average='weighted'))

#Algorithm 4 - Neural Network

param_grid={
    'alpha': [0.05, 0.01, 0.005, 0.001],
    'hidden_layer_sizes': [(5,2), (5,4), (6,2), (6,4), (8,2), (8,4), (8,6)],
    'activation': ['logistic', 'tanh', 'relu'],
    'alpha': [0.0001, 0.001, 0.01]
}

nn = MLPClassifier()
clf = GridSearchCV(nn, param_grid=param_grid)

clf.fit(X_train, y_train)

print("Tuned Hyperparameters :", clf.best_params_)

clf = MLPClassifier(solver='adam', alpha=0.01, hidden_layer_sizes=(8, 2), random_state=1, max_iter=2000, activation='logistic').fit(X_test, y_test)
prediction = clf.predict(X_test)

conf_mx = confusion_matrix(y_test, prediction)

positions = player_df["player_positions"].unique()
print(plot_confusion_matrix(conf_mx, class_names=positions))
print(" Accuracy: ",accuracy_score(y_test, prediction))
print(" F1 score: ",f1_score(y_test, prediction,average='weighted'))

# Algorithm 5 - SVM

param_grid = {
    'C': [0.1, 1, 10], 
    'gamma': [1, 0.1, 0.01, 0.001],
    'kernel': ['rbf', 'poly', 'sigmoid']
}

grid = GridSearchCV(svm.SVC(),param_grid,refit=True, cv=5)
grid.fit(X_train,y_train)

print("Tuned Hyperparameters :", clf.best_params_)

clf = svm.SVC(C = 1.0, kernel='rbf', gamma='scale', max_iter=1000).fit(X_train, y_train)
prediction = clf.predict(X_test)

conf_mx = confusion_matrix(y_test, prediction)

positions = player_df["player_positions"].unique()
print(plot_confusion_matrix(conf_mx, class_names=positions))
print(" Accuracy: ", accuracy_score(y_test, prediction))
print(" F1 score: ", f1_score(y_test, prediction, average='weighted'))

# Get support vector indices
support_vector_indices = clf.support_
print(support_vector_indices)

# Get number of support vectors per class
support_vectors_per_class = clf.n_support_
print(support_vectors_per_class)

# Get support vectors themselves
support_vectors = clf.support_vectors_

# Visualize support vectors
plt.scatter(X_train[:,0], X_train[:,1])
plt.scatter(support_vectors[:,0], support_vectors[:,1], color='red')
plt.title('Linearly separable data with support vectors')
plt.xlabel('X1')
plt.ylabel('X2')
plt.show()

"""**Dream Team Prediction**"""

def final_positions(row):
  positions = row['player_positions'].split(', ')
  N = len(positions)
  if N < 3:
    #If a player has only two positions, then we will consider the first position as the their main position
    pos = positions[0]
    if pos in ['ST', 'LW', 'RW', 'CF']:
      return 0
    elif pos in ['CAM', 'LM', 'CM', 'RM', 'CDM']:
      return 1
    elif pos in ['LWB', 'RWB', 'LB', 'CB', 'RB']:
      return 2
    elif pos in ['GK']:
      return 3
  else: #If a player has more than 3 positions
    pos_count = [0, 0, 0, 0]
    for pos in positions:
      if pos in ['ST', 'LW', 'RW', 'CF']:
        return 0
      elif pos in ['CAM', 'LM', 'CM', 'RM', 'CDM']:
        return 1 
      elif pos in ['LWB', 'RWB', 'LB', 'CB', 'RB']:
        return 2 
      elif pos in ['GK']:
        return 3 
      else:
        continue
      pos_count[index] += 1
    return pos_count.index(max(pos_count))

data['player_positions'] = data.apply(final_positions, axis=1)

avg_val=data.groupby('club_name').apply(lambda x:np.average(x['value_eur'])).reset_index(name='Average Value')
best_val=data.groupby('club_name').apply(lambda x:x['overall'].count()).reset_index(name='Player Counts')
best_avg_val=pd.merge(avg_val,best_val,how='inner',left_on='club_name',right_on='club_name')
best_avg=best_avg_val[best_avg_val['Player Counts']>=1]
best_avg.sort_values(by=['Average Value','Player Counts'],ascending=[False,False])
pe.scatter(best_avg,x='Average Value',y='Player Counts',color='Player Counts',size='Average Value',hover_data=['club_name'],title='Clubwise player counts and Average Value')

team = data.groupby('club_name')['value_eur'].mean().reset_index().sort_values('value_eur', ascending=True).tail(20)
fig = pe.bar(team, x="value_eur", y="club_name", orientation='h', color_discrete_sequence =['red']*len(team),
             title="Top 20 teams with the highest player's average value",
             labels={'value_eur': 'Value in Euros', 'club_name':'Name of the club'})
fig.show()

avg_val=data.groupby('club_name').apply(lambda x:np.average(x['overall'])).reset_index(name='Overall Ratings')
best_val=data.groupby('club_name').apply(lambda x:x['overall'].count()).reset_index(name='Player Counts')
best_avg_val=pd.merge(avg_val,best_val,how='inner',left_on='club_name',right_on='club_name')
best_avg=best_avg_val[best_avg_val['Player Counts']>=1]
best_avg.sort_values(by=['Overall Ratings','Player Counts'],ascending=[False,False])
pe.scatter(best_avg,x='Overall Ratings',y='Player Counts',color='Player Counts',size='Overall Ratings',hover_data=['club_name'],title='Clubwise player counts and Overall Rating')

team = data.groupby('club_name')['overall'].mean().reset_index().sort_values('overall', ascending=True).tail(20)
fig = pe.bar(team, x="overall", y="club_name", orientation='h', color_discrete_sequence =['red']*len(team),
             title="Top 20 teams with the highest player's average Overall rating",
             labels={'overall': 'Overall Rating', 'club_name':'Name of the club'})
fig.show()

avg_val=data.groupby('club_name').apply(lambda x:np.average(x['potential'])).reset_index(name='Potential')
best_val=data.groupby('club_name').apply(lambda x:x['overall'].count()).reset_index(name='Player Counts')
best_avg_val=pd.merge(avg_val,best_val,how='inner',left_on='club_name',right_on='club_name')
best_avg=best_avg_val[best_avg_val['Player Counts']>=1]
best_avg.sort_values(by=['Potential','Player Counts'],ascending=[False,False])
pe.scatter(best_avg,x='Potential',y='Player Counts',color='Player Counts',size='Potential',hover_data=['club_name'],title='Clubwise player counts and Highest individual potential Potential')

team = data.groupby('club_name')['potential'].mean().reset_index().sort_values('potential', ascending=True).tail(20)
fig = pe.bar(team, x="potential", y="club_name", orientation='h', color_discrete_sequence =['red']*len(team),
             title="Top 20 teams with the highest individual player potential",
             labels={'potential': 'Potential of individual player', 'club_name':'Name of the club'})
fig.show()

pos_cnt=data.groupby('team_position').apply(lambda x:x['short_name'].count()).reset_index(name='Counts')
pos_cnt.sort_values(by='Counts',ascending=False,inplace=True)
fig=pe.bar(pos_cnt,x='team_position',y='Counts',color='Counts',title='Position wise Player counts in FIFA 21', 
           labels={'team_position': 'Positions'})
fig.show()

data['attacking'] = data[['attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys']].mean(axis=1)
data['skill'] = data[['skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control']].mean(axis=1)
data['movement'] = data[['movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance']].mean(axis=1)
data['power'] = data[['power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots']].mean(axis=1)
data['mentality'] = data[['mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure']].mean(axis=1)
data['defending'] = data[['defending_standing_tackle', 'defending_sliding_tackle']].mean(axis=1)
data['goalkeeping'] = data[['goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning', 'goalkeeping_reflexes']].mean(axis=1)

#Creating a new dataset with the necessary player statistics attributes
columns = ['age', 'player_positions','attacking_crossing', 'attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys', 'skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control', 'movement_acceleration', 'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance', 'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots', 'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties', 'mentality_composure', 'defending_standing_tackle', 'defending_sliding_tackle', 'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking', 'goalkeeping_positioning', 'goalkeeping_reflexes']
player_df = data[columns]
player_df.head()

attacking=data.groupby('team_position').apply(lambda x:np.average(x['attacking'])).reset_index(name='attacking')
skill=data.groupby('team_position').apply(lambda x:np.average(x['skill'])).reset_index(name='skill')
movement=data.groupby('team_position').apply(lambda x:np.average(x['movement'])).reset_index(name='movement')
power=data.groupby('team_position').apply(lambda x:np.average(x['power'])).reset_index(name='power')
mentality=data.groupby('team_position').apply(lambda x:np.average(x['mentality'])).reset_index(name='mentality')
defending=data.groupby('team_position').apply(lambda x:np.average(x['defending'])).reset_index(name='defending')
goalkeeping=data.groupby('team_position').apply(lambda x:np.average(x['goalkeeping'])).reset_index(name='goalkeeping')

pos_overall1=pd.merge(attacking,skill,how='inner',left_on='team_position',right_on='team_position')
pos_overall2=pd.merge(movement,power,how='inner',left_on='team_position',right_on='team_position')
pos_overall3=pd.merge(mentality,defending,how='inner',left_on='team_position',right_on='team_position')
pos_overall4=pd.merge(goalkeeping,goalkeeping,how='inner',left_on='team_position',right_on='team_position')
pos_overall11=pd.merge(pos_overall1,pos_overall2,how='inner',left_on='team_position',right_on='team_position')
pos_overall22=pd.merge(pos_overall3,pos_overall4,how='inner',left_on='team_position',right_on='team_position')
pos_overall12=pd.merge(pos_overall11,pos_overall22,how='inner',left_on='team_position',right_on='team_position')
pos_overall=pd.merge(pos_overall12,goalkeeping,how='inner',left_on='team_position',right_on='team_position')

print('Overall Attributes of the Players in FIFA 21')
fig=plt.figure(figsize=(70,70))

for i in range(0,25):
    labels=np.array(['attacking',
                     'skill', 
                     'movement', 
                     'power',
                     'mentality',
                     'defending',
                     'goalkeeping'])
    stats=pos_overall.loc[i,labels].values
    
    angles=np.linspace(0, 2*np.pi, len(labels), endpoint=False)
    # close the plot
    stats=np.concatenate((stats,[stats[0]]))
    angles=np.concatenate((angles,[angles[0]]))

    ax = fig.add_subplot(9,3,i+1, polar=True)
    ax.plot(angles, stats, 'o-', linewidth=1)
    ax.fill(angles, stats,color='red',alpha=0.25)
    ax.set_thetagrids(angles * 180/np.pi, labels)
    ax.set_title([pos_overall.loc[i,"team_position"]])
    ax.grid(True)

#Categorizing the top skills for different player positions that we have

player_position  = pd.DataFrame()
for position_name, features in player_df.groupby(data['team_position'])[columns].mean().iterrows():
    top_features = dict(features.nlargest(5))
    player_position[position_name] = tuple(top_features)

player_position

#Getting the top players in each category for the dream team

position = []
player = []
club_l = []
for col in player_position.columns:
    tmp_df = pd.DataFrame()
    l = [player_position[col].values]
    l = l[0]
    l = list(l)
    l.append('short_name')
    tmp_df = pd.DataFrame.copy(data[data['team_position'] == col][l])
    tmp_df['mean'] = np.mean(tmp_df.iloc[: , :-1] , axis = 1)
    name = tmp_df['short_name'][tmp_df['mean'] == tmp_df['mean'].max()].values[0]
    club = data['club_name'][data['short_name'] == str(name)].values[0]
    position.append(col)
    player.append(name)
    club_l.append(club)
    
gk = ['GK']
forward = ['LS', 'ST', 'RS','LF', 'CF', 'RF']
midfeilder = ['LW','RW', 'LAM', 'CAM', 'RAM', 'LM', 'LCM', 'CM',
              'RCM', 'RM', 'LDM', 'CDM', 'RDM' ]
defenders = ['LWB','RWB', 'LB', 'RB', 'LCB', 'RCB', 'CB',]

print('GoalKeeper : ')
for p , n , c in zip(position , player , club_l):
    if p in gk:
        print('{} [Club : {} , Position : {}]'.format(n , c , p))
print('\nFORWARD : ')
for p , n , c in zip(position , player , club_l):
    if p in forward:
        print('{} [Club : {} , Position : {}]'.format(n , c , p))
print('\nMIDFEILDER : ')
for p , n , c in zip(position , player , club_l):
    if p in midfeilder:
        print('{} [Club : {} , Position : {}]'.format(n , c , p))
print('\nDEFENDER : ')
for p , n , c in zip(position , player , club_l):
    if p in defenders:
        print('{} [Club : {} , Position : {}]'.format(n , c , p))

"""![picture](https://drive.google.com/uc?export=view&id=1tF7PcV5buSOWWwhX01LG4XjQOyaEHqpO)


"""

#Predicting the dream team based on highest potential
final_team=data[['short_name','age','potential','team_position','club_name']]
final_team.sort_values(by='age',inplace=True)
pos_play=final_team.groupby('team_position').apply(lambda x:np.max(x['potential'])).reset_index(name='potential')
player_pos=pd.merge(final_team,pos_play,how='inner',left_on=['team_position','potential'],right_on=['team_position','potential'])
pos_best=player_pos[['short_name','club_name','age','team_position','potential']]
cm = sns.light_palette("green", as_cmap=True) 
pos_best.style.background_gradient(cmap=cm).set_precision(2)

"""![picture](https://drive.google.com/uc?export=view&id=1SBTBZ0wZ_OHjnAai8ZVa92fwGHnB8lDm)


"""

#Predicting the dream team based on overall ratings
final_team=data[['short_name','age','overall','team_position','club_name']]
final_team.sort_values(by='age',inplace=True)
pos_play=final_team.groupby('team_position').apply(lambda x:np.max(x['overall'])).reset_index(name='overall')
player_pos=pd.merge(final_team,pos_play,how='inner',left_on=['team_position','overall'],right_on=['team_position','overall'])
pos_best=player_pos[['short_name','club_name','age','team_position','overall']]
cm = sns.light_palette("yellow", as_cmap=True) 
pos_best.style.background_gradient(cmap=cm).set_precision(2)